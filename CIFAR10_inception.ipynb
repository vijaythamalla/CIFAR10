{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbFbonAbizhoJLMkLoek7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaythamalla/CIFAR10/blob/master/CIFAR10_inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LAJ-NKUeEc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os,datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Dense,Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout,Conv2D,MaxPool2D\n",
        "from tensorflow.keras.layers import LeakyReLU,Input,Activation\n",
        "from tensorflow.keras.optimizers import SGD,Adam,Nadam\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCPQvq4xeQug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "863ac685-aeaf-4795-d249-0622409adb2c"
      },
      "source": [
        "(X_train,y_train),(X_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F92jwINceYEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c766564-4709-47b5-a771-e2555c8c8781"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjOsEsOVeda1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58883f84-81cc-488d-aa0f-28f2a60800dc"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8w6QTAceeOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b282ed66-deac-4670-ec8a-a9ec1619fc0a"
      },
      "source": [
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff46d10cdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfMklEQVR4nO2da2yc53Xn/2dunOGdFC+SKNmy5UvtNLbiqIbXyXaTBi3coKgTYJFNPgT+EFRF0QAN0P1gZIFNFtgPyWKTIB8WWSgbt+4im8vm0hiFsW1qpDDaFK7l2PG9tizLkSiKokRS5HCGcz37YcZb2fv8H9IiOVTy/H+AoOF7+LzvmWfe877zPn+ec8zdIYT41Sez2w4IIXqDgl2IRFCwC5EICnYhEkHBLkQiKNiFSITcVgab2X0AvgogC+B/uPsXYr+fz+e9r1gM2lqtFh2XQVgezBo/ViHHr2P5iC2XzVKbWfiAZpFrZsTHZpO/55ggmo35SKTUtrf5sdr8aJaJvIEI7Xb4vcV8j+4v4r9FJpnZMhE/shn+ebJzAADaERnbYycCGxPdX5jF5VWUK+vBg111sJtZFsB/A/DbAM4CeNLMHnH3F9mYvmIRR+56b9C2vLxIj9WXCX/Q4wU+Gdft6ae2yfEBapsYHaS2QjYf3J7rK9ExyPIpXlxaprZ6k7+3sdERasu0GsHttVqNjllfX6e2Yil8cQaAFvjFqlItB7ePjA7TMXC+v3qtTm1ZhD8XgF9chgb55zwwwM+PfJ7PRzXio8duCJnwORJ7z00PXzy++I3v88NwDzbkbgAn3f2Uu9cBfBvA/VvYnxBiB9lKsM8AOHPFz2e724QQ1yBbembfDGZ2DMAxAOjr69vpwwkhCFu5s88COHjFzwe6296Cux9396PufjSX589WQoidZSvB/iSAm83sBjMrAPg4gEe2xy0hxHZz1V/j3b1pZp8G8NfoSG8PufsLsTHr6+t44cXwryxfvEjHjZMFUNvDV0YnWkPUZqUpaltrc1Wg3AqvkLsV6JjKOl9RrVT5CnmjxaWmixHNsZgL+9hs8v1lyWowEH/0qqyvUVuzHX7ftr6HjslEVLlGRE0o5fh5UCYr2outJh3T389X4y3Dv50aUWsAABE5r7IeVlCajfB2AMjmwp9LY71Kx2zpmd3dHwXw6Fb2IYToDfoLOiESQcEuRCIo2IVIBAW7EImgYBciEXb8L+iuJAOglCOyUeSP664nEtuhaZ4QMjU5Tm2lmLQSyWqq1sIJI+sNLgt5ZH+FUiSBJpII421+vJHxcAJQs8H3V8hzPyLJiMgW+IdWq4fnqtHk89Ef2V9ugPtYjIxrWlgezESy6JqRDLVYpuXgAE++Kq9VqK3RDEtssYTD1ZXLwe3taPaoECIJFOxCJIKCXYhEULALkQgKdiESoaer8WaOooUTEIaGuCu3zIwFt+8p8cyJfJuXWiov8uSUVptf/6qVsO8ZngeD4UiZq1xkFXn58iofF/nUxofCK8KrKzxppR5JaKmSJA0gXldtkJR2atR5okamxd9YPpKQ0yKluAAgR5bPazU+ppDnH2imzRNoauUlagNJogKAPnIaN9tcMbi8FlZkWpF6grqzC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhF6Kr3lzDDWFz5kKSKtjJAkiMlhXvOrRdoPAYj0MQGyuUghNFJHrNaOSD8RnSwXScZo1bhE5Vl+jb5wIdxlptXg73q1wpM0Ki0uUw6WIt1daqT9E/h7zhiXjbJ9kU4sa1xm7c+HfcxFWiutR+oGVhtcemtHmnYtl7mPy5Xw+VMmUi8ArDfC50A9UmtQd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwpakNzM7DWAVHTWr6e5HowfLGiZHwxLKUJ5LXsVi2JbJcqmjFKnv1mhyGaodyeTqtKH//6lH6sW16lyWa3skoywieXmOZ2Wt1sMZbK0Wn99KpNVUM2JbXeP+zy6G/chn+P6Gy3zuG+d5e7DqZS4dXjdxU3D71NQBOsaGwvXdAKC2dInaymWePXh5lUtvFy+HZdbTZ7gfrWw4dGt1Ltdth87+QXfnn4QQ4ppAX+OFSIStBrsD+Bsze8rMjm2HQ0KInWGrX+Pf7+6zZjYF4Mdm9rK7P37lL3QvAscAoBh5LhdC7CxburO7+2z3/wsAfgjg7sDvHHf3o+5+tJDTU4MQu8VVR5+ZDZjZ0JuvAfwOgOe3yzEhxPayla/x0wB+2G2XlAPwv9z9/8QG5HNZ7J8MFyIcLnDJYLA/LDVZRLpCJAPJItlmtSqXcTJEltszxNtQDQzwbK2Vy1zEGBnmGWWrkSKQb8yG91mu8UeoAp8OzPRHsvbyPDPv9KVw9l3NI0VCI1lvI8ND1Hbv7VzxXZkLy6xeiRxrgmdT1ip8Psplfu/sy/N9Htwbfm9TU9N0zPxKWMq79Mp5Ouaqg93dTwG482rHCyF6ix6ihUgEBbsQiaBgFyIRFOxCJIKCXYhE6G3ByaxhfCicjZarh6UaAOjLh93s7wv3NQOAWpXLU41Iv67R0XBfOQBwUqSw3uLXzEYjUgxxkPeBO7cQ7uUFAK+9wbOhFlbD7y1SuxDXR3rmfeRfH6G2A/u4/9976lRw+z+e5NJQs80z/XIZLpWtLi9QW6UcnsehIS6FocWz74pFPq5AsjMBoN/4uGYr/OFcd3A/HTO0GO4F+OzrfC50ZxciERTsQiSCgl2IRFCwC5EICnYhEqG3q/G5HKbG9wRt1UW+ap2xsJtl0jYHAKqxWlwWqccWaZPErozVBl9FHh3jCS31Fl9hPnX2HLUtrnAfWX26bKRl1HCR728qF171BYDiIlcMbh7eG9w+N879mF++QG21Cp/jp195hdoypB1SYyDSumqEJ6Agw0NmZISrQ0PtSLspUqfQ6yt0zCGSUNaX5/OrO7sQiaBgFyIRFOxCJIKCXYhEULALkQgKdiESocfSWx5jE5NB29ggb9eUyYSTCJZXluiYxlqZ768Va//EC7I5ScgZHOR15hrgtpdOcclorcZbCRWLfdxWCPtYGuCy0FiWy5RPnZyntmadnz61kbD0NjnG58PA5bBGk0uzlTqvhbdGas3Vm/w9W0RKjXQHQz4TaR2WidTey4XnsVnj0qYT2ZbkagHQnV2IZFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsKH0ZmYPAfg9ABfc/de728YBfAfAIQCnAXzM3bkO9i97A4iMZpH2OIy+SD2wfoSzggAgF7nGZTKRenJElusr8fZPF8/zrLHKRT5lN45ziarGVSgUicR26+EZOiYT2WEzy+d4JSJ95rLhOnlDBf657Bk7TG2Hb76O2l7/xZPU9vIrs8HthVxE1nIu2zabPGQyJOMQAPIFPo/tdvi8akd0PrPweRpRBjd1Z/9zAPe9bduDAB5z95sBPNb9WQhxDbNhsHf7rS++bfP9AB7uvn4YwEe22S8hxDZztc/s0+4+1319Hp2OrkKIa5gtL9B5p5g6/SM9MztmZifM7MRqJfKwKYTYUa422OfNbB8AdP+n9YTc/bi7H3X3o0P9fNFJCLGzXG2wPwLgge7rBwD8aHvcEULsFJuR3r4F4AMAJszsLIDPAfgCgO+a2acAvAHgY5s5WNsd1fVwcT1r8MwlIJyhtLbGC/LVG/w61szwbxjlCpfKVoht5iCfRm/y/V0/wYWSw/u5VFNZ5+NmbrkzuL3g/BFq6TIv3FkaDRcIBQBc4plcB/fuC25fXuPZfDf+2s3UNjzGs/aGx26jtqWF8PwvXeYttPIReTDjPOOw0Y5kU/JkSrQa4fM7kkRHW5FFkt42DnZ3/wQxfWijsUKIawf9BZ0QiaBgFyIRFOxCJIKCXYhEULALkQg9LTjpcLQsLE94ixcAZDJDqciLVA4Ocanm3AKX+V4/u0BtuXzYj8I878u2Ps/3d/MUl9c+9AEuQ702+/ZUhX9haCZc0HNiT7gAJABcWOBFJUdHIzJUm/tfIAUWLyyEs9AAIFdcpraF5Tlqm53jWWr5fPg8GB3mWli1ygUsz/H7o0W0snZElstYeJxFMjAjbQL5cd75ECHELyMKdiESQcEuRCIo2IVIBAW7EImgYBciEXoqvWWzGYyODgZtzRyX3srlcMaWN7iccXmVZzW98QsuNZXLXMYpFcPXxrnXefbddJEXIZyZuZ7aRvffQG351UgKFSnCeeDOu/mQ81wOKzW5dNgCz6RbWwvb9vWHpUEAqLf4+7KB8HkDAAcG9lPb0GhYcly9dJ6OuTB/idoaxuXG9TovYokM18oG+sJZmPVqRFIkBSyNyHiA7uxCJIOCXYhEULALkQgKdiESQcEuRCL0dDW+3WpidTm80pmr81ptedLqBrwEGnJZbqyU+Ur92BBP/BgdCK+aVpf4avzUfl7DbeaOf0Ntz5+tU9srJ7nt3n3jwe3Ly3zM9OFw3ToAyKBCbfUaX6kf9fDK+soFvtJdqvNaePvGw+8LAJZbvC5c/o6x4PZqJLHmHx59hNrOnuHvORtp8RRrzMTybhqxNmWN8FyxpDFAd3YhkkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwmbaPz0E4PcAXHD3X+9u+zyAPwDwpg7xWXd/dDMHzBIFohX5o38nskWGtIUCgJZx6W2JKzxYWYnUH6uF5at9I1yu+40PfpDaDtx6D7X94M8eora9kaSQbD1cX2/21Gt8fzfeTm3FPTdR24BzubSyGO71WWqHpTAAqFe5zHdxldtGJ3nS0J69h4Lbq+VhOibDTWgVePJPrAZdo8GlT2uGE7rMeaJXsxkO3a1Kb38O4L7A9q+4+5Huv00FuhBi99gw2N39cQC8nKkQ4peCrTyzf9rMnjWzh8yMfzcTQlwTXG2wfw3AYQBHAMwB+BL7RTM7ZmYnzOxEucKfW4QQO8tVBbu7z7t7y93bAL4OgJZBcffj7n7U3Y8O9vOqLUKIneWqgt3M9l3x40cBPL897gghdorNSG/fAvABABNmdhbA5wB8wMyOAHAApwH84WYOZgCMKAMtksUD8DY4kU488Gpkf5ESbuN7eNuovf1hqe+uo7fQMbfdy+W1pQtcbuxr8sy8Gw8coLY2eXN7p3jtt+Y6lzArkWy5epOPa1TDp1YLXDZ8bfYstT33/Alqu/ce7uOeveGsw5XVsDQIAKRjFABg4hCXWduxdk31iIxGJN3LC7wdVm017GSbZBsCmwh2d/9EYPM3NhonhLi20F/QCZEICnYhEkHBLkQiKNiFSAQFuxCJ0NOCk+5Am2T4VGtcMiiQLK9cjhf4y2a4HHPTXv7XvcUSv/4duv5gcPud7+eZbftuvYPanvnHP6O26w5yH/e+693UVpg8HNye6x+hYyrrXAKsrvDMtvlzZ6htaT4so7UaPHutNBQu6AkAExP8sz5z7mlqm943E9zerESyLKu8jZOtLVFby8MZhwDgTHMGUOoLv7fCXv6eV/pIJmgkonVnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCL0VHozM+Sz4UMuRQoKttbDMkOpv0THZDNc6piKZLadmeOZRofvCpXiAw68O7y9A5fQGqtr1DYyxKWyyVuOUNtaLtwT7YWnn6RjalXux8oKn4+Ls7+gtmwrLH0Wi/yUm7khLJMBwB238MKXzSzPRMtnR8PbCzwrMrfOi0pW3pilNiYrA0Azclstk76E/Xv4+5omPQTz+Uh/OO6CEOJXCQW7EImgYBciERTsQiSCgl2IROhtIky7jVo1vNLZ38ddsWJ4tTKf4TXQvMVtpUHeGur3/93vU9u9v/uh4PbhiWk6Zv7US9SWjfi/vMpr0C2c/mdqO7caXhH+u7/8SzpmsMQTLtZrPGFk7zRXDIaHwivJr5/lyTP1yHyM7z9Ebbe8+73UhlZfcPPiMq93VyHqDwAsVbmP5vwcXq/yRK8yadnkZa4K3BYWGdDmIpTu7EKkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiEzbR/OgjgLwBMo9Pu6bi7f9XMxgF8B8AhdFpAfczdeYEuAA5H20ltuDZPIrBmWLZoeqTFU6TmV7FvmNqOvJfLOH35sET14jO8BtrSudeorVbj0srq0iK1nTn5IrWVPZwclG/xYw3muBQ5XOTJGJNjXHqbmz8f3N6MtPmqrHKZ78zrPOkGeIFayuVwDb1ijp8fzb4parvU5OdOqcRr6PUP8aStUi4sD65WVuiYZjssAUaUt03d2ZsA/tTdbwdwD4A/NrPbATwI4DF3vxnAY92fhRDXKBsGu7vPufvPuq9XAbwEYAbA/QAe7v7awwA+slNOCiG2zjt6ZjezQwDeA+AJANPuPtc1nUfna74Q4hpl08FuZoMAvg/gM+7+locJd3eQxwUzO2ZmJ8zsxFqV13IXQuwsmwp2M8ujE+jfdPcfdDfPm9m+rn0fgGDDa3c/7u5H3f3oQKmwHT4LIa6CDYPdzAydfuwvufuXrzA9AuCB7usHAPxo+90TQmwXm8l6ex+ATwJ4zsye6W77LIAvAPiumX0KwBsAPrbxrhxAWEZrN/lX/Fw+XDOuFan5VQfPTpoe4XXh/vqRv6K28emwxDO1L9wWCgDqFZ69ls+HJRcAGBzgEk8uw6WyASIP7p0K1ywDgOoqV0xLWe7jpYWL1Naohz+boSKXoOplLr29+vQJapt7+RVqqzVJS6Y8n8NWbH4PcCkSA/wczvRx6bNIZLQx8Lm67V03BLeXiqfomA2D3d3/HgDL+QvnfAohrjn0F3RCJIKCXYhEULALkQgKdiESQcEuRCL0tOAk3NBuhxf2C5HMq2KOFOvL8MKAHmkJ1K7zzKuLF8PZWgBQXgjbSg2endQGf1/jY1wOG90/SW3NVo3aZs+FffRIPlQmw0+DepNLmFnjhSoHimG5lCQwdvYXM0ayGFt1Lm9myPm2UuFyY72PyHUAhvbzuV8r8VZZq20uy62vhe+5e4ZvpGMmiJSay/PPUnd2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJEJvpTcYMhbOoir28QwfJxlsA6WwvAMAA0MT1FZp8AykPUM85z5H/Khfnqdj2hm+v0qeS03T0+GsJgBo17mMc+sdB4Lbf/qTx+iYuleoLW9c3qyW+bjhoXDWXiHHT7msRfqhrfPP7PU5LqMtL4c/s5qt0TGTt/B74MxoJGvP+We9dJHPVWE9LGEOzEQyFSvhrMJ2RL3UnV2IRFCwC5EICnYhEkHBLkQiKNiFSISersZnDCjkwteXSo0nGGRJC6J2pD5apcGTGbJ5nlTRV+Crrfl82I9CP2+DNDLME3LOL/BV/MpMeFUdAKYO3kRtsxfCdeHe9Rvvo2PKC+eo7dQrvLXSWpknfuSy4fkfGeG19YzUJwSAuVnu4y/eiCTC9IXnf3iaKzmT4xEfI6qALfLPemyJh9rM1Hhw+4FRfg6cfDGc8FSr8iQv3dmFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCBtKb2Z2EMBfoNOS2QEcd/evmtnnAfwBgIXur37W3R+NHixnmJ4MX18aly7RcdVWWJJZ47kM8AxvDZWLJGMMD/PkgwJprVRd4zXoSpGaYKhz24mf/pTabryVS3Znz4YlmUykXl9/H68ll43Im6USl5rWymHprVrlkmgz0gJssMT9uPc9t1BbkSTkNLO8tl6rwZNWqme49JZZLVLbVP8Qtb3nlneFx4zyLuhPzb0e3N5s8Pe1GZ29CeBP3f1nZjYE4Ckz+3HX9hV3/6+b2IcQYpfZTK+3OQBz3derZvYSgJmddkwIsb28o2d2MzsE4D0Anuhu+rSZPWtmD5kZb40qhNh1Nh3sZjYI4PsAPuPuKwC+BuAwgCPo3Pm/RMYdM7MTZnZipcKfyYQQO8umgt3M8ugE+jfd/QcA4O7z7t5y9zaArwO4OzTW3Y+7+1F3Pzrczyt5CCF2lg2D3cwMwDcAvOTuX75i+74rfu2jAJ7ffveEENvFZlbj3wfgkwCeM7Nnuts+C+ATZnYEHTnuNIA/3GhHhYLhuoPhu/uIcdni5JmwFDK/wLPX6i0u1QwO8re9VuEZVK12Obg9G7lmLi5wSXG1zGWS9Qb3I+vcNjQYXjqZP79Ix5xd43JS27lkNz3JZUprh7OvlpZ5vbi+Af6ZjY5w6aqQ5fNfqxMJNsflxrUa31+9HGl51ebjbjq4l9r27w3P45mzXGK9tBCOiWakhdZmVuP/HkDoE49q6kKIawv9BZ0QiaBgFyIRFOxCJIKCXYhEULALkQg9LTiZzRmGx0jmGJESAGBsKhs2DPCigRfneQHL9Uj7pFyBFxtkw9oNnmHXaHE/Lle5DDUQyfJar3CprLoeLjhZj/jYitjcydwDKK9E2j8Nhwt3Dg/z4pzVKt/fxUt8rgYHefadZcL3M2ty2baQ40VH+7hCjEKBz9Whmw5RW7US9uXxx1+kY5595UJ4X+tcztWdXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EInQU+nNzJArhg9ZHOa57uOD4WtSrsplrXyJZ/+sRPpuocWvf6XiVHhInh+rVeP90Ar93I98js9HNsslx5qHfak3uNzokcw24woVvM4lwBYx5SPZZihwuXF5iUtv1TrvbzYyGpZSc0SSA4BMZO4r4NLW/MVValuKZDiuroWzGP/2717mxyIq5Xpd0psQyaNgFyIRFOxCJIKCXYhEULALkQgKdiESoafSW7ttKLOCfdlBOm5wIKzj5EtcFxqIpCeNjHCprLzCe5GVV8IFAMuVSNbbOrcNFXjBxiLpKwcAzRqXHHO58PW7ELms5/t4tpYZH9gfKdyZIaZmi0tDhVKkB98olxsXF7nktUqkyOFxPveVSM+5V0/zAqIvP3eG2qbHeTbl9AHy3jL8PJ0gBTjnV7kMqTu7EImgYBciERTsQiSCgl2IRFCwC5EIG67Gm1kRwOMA+rq//z13/5yZ3QDg2wD2AHgKwCfdPdqmtV4Hzr4RttWW+er50GR4BbdYiiRA8MV9jI/zt11e43XQlpfDtqVLPHFiiS/eItvmq+Bt50pDq8VX+NEO22JXdcvwRJhsjs9VNZI05GTRPU/aQgFAs8JbVLUi9elakeSa5XJ4HOsKBQCLEUXm9En+gS5fWqO2+ho/4N6RcGuo266foWOYi6+eX6FjNnNnrwH4LXe/E532zPeZ2T0AvgjgK+5+E4AlAJ/axL6EELvEhsHuHd7saJjv/nMAvwXge93tDwP4yI54KITYFjbbnz3b7eB6AcCPAbwGYNn9/31ZOwuAf+cQQuw6mwp2d2+5+xEABwDcDeDXNnsAMztmZifM7MTlMi92IITYWd7Rary7LwP4CYB/BWDUzN5cvTkAYJaMOe7uR9396MhgpMK+EGJH2TDYzWzSzEa7r0sAfhvAS+gE/b/t/toDAH60U04KIbbOZhJh9gF42Myy6Fwcvuvuf2VmLwL4tpn9ZwBPA/jGRjtyy6GVnwjaGoWjdFytHU78yDTDrY4AoDjC5aTRSf4NYyzDEzXGK+HEhOVF3i5o+SKX16prfPpbTS7nwfk1ut0M+7he5Y9QhUKk3l2O+7+6zhM1quSRLR9RZ4cy4eQOAGhnuKTUaPB57BsIS5jFPK93N1rgPt6IUWp79528DdWtd9xJbYduuim4/e57uNx49lw5uP0fXuMxsWGwu/uzAN4T2H4Kned3IcQvAfoLOiESQcEuRCIo2IVIBAW7EImgYBciEcwj2VXbfjCzBQBv5r1NAOA6Qe+QH29FfryVXzY/rnf3yZChp8H+lgObnXB3Lq7LD/khP7bVD32NFyIRFOxCJMJuBvvxXTz2lciPtyI/3sqvjB+79swuhOgt+hovRCLsSrCb2X1m9s9mdtLMHtwNH7p+nDaz58zsGTM70cPjPmRmF8zs+Su2jZvZj83s1e7/Y7vkx+fNbLY7J8+Y2Yd74MdBM/uJmb1oZi+Y2Z90t/d0TiJ+9HROzKxoZv9kZj/v+vGfuttvMLMnunHzHTOLpEYGcPee/gOQRaes1Y0ACgB+DuD2XvvR9eU0gIldOO5vArgLwPNXbPsvAB7svn4QwBd3yY/PA/j3PZ6PfQDu6r4eAvAKgNt7PScRP3o6JwAMwGD3dR7AEwDuAfBdAB/vbv/vAP7onex3N+7sdwM46e6nvFN6+tsA7t8FP3YNd38cwNvrJt+PTuFOoEcFPIkfPcfd59z9Z93Xq+gUR5lBj+ck4kdP8Q7bXuR1N4J9BsCV7S53s1ilA/gbM3vKzI7tkg9vMu3uc93X5wFM76IvnzazZ7tf83f8ceJKzOwQOvUTnsAuzsnb/AB6PCc7UeQ19QW697v7XQB+F8Afm9lv7rZDQOfKjs6FaDf4GoDD6PQImAPwpV4d2MwGAXwfwGfc/S2laXo5JwE/ej4nvoUir4zdCPZZAAev+JkWq9xp3H22+/8FAD/E7lbemTezfQDQ/f/Cbjjh7vPdE60N4Ovo0ZyYWR6dAPumu/+gu7nncxLyY7fmpHvsd1zklbEbwf4kgJu7K4sFAB8H8EivnTCzATMbevM1gN8B8Hx81I7yCDqFO4FdLOD5ZnB1+Sh6MCdmZujUMHzJ3b98hamnc8L86PWc7FiR116tML5ttfHD6Kx0vgbgP+ySDzeiowT8HMALvfQDwLfQ+TrYQOfZ61Po9Mx7DMCrAP4WwPgu+fE/ATwH4Fl0gm1fD/x4Pzpf0Z8F8Ez334d7PScRP3o6JwDuQKeI67PoXFj+4xXn7D8BOAngfwPoeyf71V/QCZEIqS/QCZEMCnYhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiET4vyrWWZ/xQ9u6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhLNrH8feiv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "066eb5cf-bf16-47bf-8e0a-20928f9e604e"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HSAUWkXeo7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Fl0AX3fV7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "584d8a34-ce3f-447b-cd32-bf422f882005"
      },
      "source": [
        "classes[int(y_train[0])]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'frog'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMiMreD1fsdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cYiRUq_f6wQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logs_base_dir = \"./logs\"\n",
        "log_dir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "filepath= os.path.join(logs_base_dir,'model.{epoch:02d}-{val_loss:.2f}.h5')\n",
        "\n",
        "os.makedirs(logs_base_dir, exist_ok=True)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir),\n",
        "    #tf.keras.callbacks.ReduceLROnPlateau()\n",
        "]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRVoCaevlMko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inception(layer_in,f1,f3_in,f3_out,f5_in,f5_out,fp):\n",
        "    # 1x1 conv layer\n",
        "    conv1 = Conv2D(f1,1,1,padding='same')(layer_in)\n",
        "    conv1 = LeakyReLU(0.2)(conv1)\n",
        "    conv1 = Dropout(0.2)(conv1)\n",
        "    # 3x3 conv layer\n",
        "    conv3 = Conv2D(f3_in,1,1,padding='same')(layer_in)\n",
        "    conv3 = LeakyReLU(0.2)(conv3)\n",
        "    conv3 = Conv2D(f3_out,3,1,padding='same')(conv3)\n",
        "    conv3 = LeakyReLU(0.2)(conv3)\n",
        "    conv3 = Dropout(0.2)(conv3)\n",
        "    # 5x5 conv layer\n",
        "    conv5 = Conv2D(f5_in,1,1,padding='same')(layer_in)\n",
        "    conv5 = LeakyReLU(0.2)(conv5)\n",
        "    conv5 = Conv2D(f5_out,5,1,padding='same')(conv5)\n",
        "    conv5 = LeakyReLU(0.2)(conv5)\n",
        "    conv5 = Dropout(0.2)(conv5)\n",
        "    # MaxPooling layer\n",
        "    pool = MaxPool2D(3,1,padding='same')(layer_in)\n",
        "    pool = Conv2D(fp,1,1,padding='same')(pool)\n",
        "    pool = LeakyReLU(0.2)(pool)\n",
        "\n",
        "    output = keras.layers.concatenate([conv1,conv3,conv5,pool])\n",
        "    return output"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqGZV1FWlNm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ffd21d3-1f89-404f-b315-2f7c2b752ce9"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "inputs = Input(shape=(X_train.shape[1:]))\n",
        "\n",
        "conv_m1 = Conv2D(32,kernel_size=3,padding='same')(inputs)\n",
        "pool_m1 = MaxPool2D(2)(conv_m1)\n",
        "\n",
        "layer_1 = inception(pool_m1,32,32,64,32,32,32)\n",
        "conv_m2 = Conv2D(64,kernel_size=3,padding='same')(layer_1)\n",
        "bn_m1 = BatchNormalization()(conv_m2)\n",
        "act_m1 = LeakyReLU(0.2)(bn_m1)\n",
        "drop_m1 = Dropout(0.2)(act_m1)\n",
        "pool_m2 = MaxPool2D(2)(act_m1)\n",
        "\n",
        "layer_2 = inception(pool_m2,32,32,64,32,32,32)\n",
        "conv_m3 = Conv2D(128,3,1,padding='same',activation='relu')(layer_2)\n",
        "bn_m2 = BatchNormalization()(conv_m3)\n",
        "act_m2 = LeakyReLU(0.2)(bn_m2)\n",
        "drop_m2 = Dropout(0.5)(act_m2)\n",
        "\n",
        "#pool_2 = MaxPool2D(2)(layer_2)\n",
        "flat = Flatten()(drop_m2)\n",
        "#hidden = Dense(128,activation='relu')(flat)\n",
        "output = Dense(10,activation='sigmoid')(flat)\n",
        "\n",
        "model = keras.Model(inputs=inputs,outputs=output)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizers = Adam()\n",
        "\n",
        "model.compile(optimizer=optimizers,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,y_train,batch_size=32,epochs=100,validation_split=0.2,callbacks=callbacks)\n",
        "\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 32)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 32)   1056        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 32)   1056        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 32)   1056        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 64)   18496       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   25632       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 16, 16, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 32)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 32)   1056        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 16, 16, 32)   0           leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16, 16, 64)   0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 16, 16, 32)   0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 32)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16, 16, 160)  0           dropout[0][0]                    \n",
            "                                                                 dropout_1[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "                                                                 leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   92224       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 16, 16, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 32)     2080        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 32)     0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 32)     0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 32)     2080        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 64)     18496       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 32)     25632       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 32)     0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 64)     0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 32)     0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 32)     2080        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 8, 32)     0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 8, 8, 64)     0           leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 8, 8, 32)     0           leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 8, 8, 32)     0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 160)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "                                                                 leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 128)    184448      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 8, 8, 128)    512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 8, 8, 128)    0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 8, 8, 128)    0           leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8192)         0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           81930       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 461,066\n",
            "Trainable params: 460,682\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "   2/1250 [..............................] - ETA: 1:41 - loss: 2.6998 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.1475s). Check your callbacks.\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 1.8093 - accuracy: 0.3794 - val_loss: 2.2509 - val_accuracy: 0.4266\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 1.4329 - accuracy: 0.5094 - val_loss: 1.3803 - val_accuracy: 0.5481\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 1.1536 - accuracy: 0.6090 - val_loss: 1.4343 - val_accuracy: 0.5557\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.9677 - accuracy: 0.6688 - val_loss: 0.9769 - val_accuracy: 0.6707\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.8269 - accuracy: 0.7158 - val_loss: 1.0204 - val_accuracy: 0.6688\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.7414 - accuracy: 0.7435 - val_loss: 0.9312 - val_accuracy: 0.7065\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6740 - accuracy: 0.7634 - val_loss: 0.7432 - val_accuracy: 0.7466\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6145 - accuracy: 0.7855 - val_loss: 0.7423 - val_accuracy: 0.7545\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.5718 - accuracy: 0.7988 - val_loss: 0.7845 - val_accuracy: 0.7430\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.5308 - accuracy: 0.8146 - val_loss: 0.6703 - val_accuracy: 0.7812\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.5042 - accuracy: 0.8244 - val_loss: 0.7055 - val_accuracy: 0.7660\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.4673 - accuracy: 0.8365 - val_loss: 0.6554 - val_accuracy: 0.7851\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.4394 - accuracy: 0.8450 - val_loss: 0.7075 - val_accuracy: 0.7713\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.4155 - accuracy: 0.8537 - val_loss: 0.6728 - val_accuracy: 0.7856\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.3937 - accuracy: 0.8601 - val_loss: 0.6853 - val_accuracy: 0.7882\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.3768 - accuracy: 0.8656 - val_loss: 0.6954 - val_accuracy: 0.7835\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.3610 - accuracy: 0.8724 - val_loss: 0.6170 - val_accuracy: 0.8042\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.3384 - accuracy: 0.8788 - val_loss: 0.7518 - val_accuracy: 0.7790\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.3253 - accuracy: 0.8850 - val_loss: 0.6546 - val_accuracy: 0.7980\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.3031 - accuracy: 0.8928 - val_loss: 0.6702 - val_accuracy: 0.8063\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.2917 - accuracy: 0.8967 - val_loss: 0.8750 - val_accuracy: 0.7525\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2830 - accuracy: 0.8989 - val_loss: 0.6377 - val_accuracy: 0.8167\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2722 - accuracy: 0.9026 - val_loss: 0.7967 - val_accuracy: 0.7851\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2577 - accuracy: 0.9087 - val_loss: 0.7405 - val_accuracy: 0.7899\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2463 - accuracy: 0.9117 - val_loss: 0.6616 - val_accuracy: 0.8022\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2385 - accuracy: 0.9143 - val_loss: 0.8736 - val_accuracy: 0.7696\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.2399 - accuracy: 0.9148 - val_loss: 0.6496 - val_accuracy: 0.8191\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6224 - accuracy: 0.8008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6223564743995667, 0.8008000254631042]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_I1T01tf_Fl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "755e6f0d-c86a-457c-e13b-1cf17ccc9bc5"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = Sequential([\n",
        "        # Input Layer\n",
        "        Conv2D(32,kernel_size=3,padding='same',input_shape=X_train.shape[1:]),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        keras.layers.MaxPool2D(2),\n",
        "        Conv2D(64,kernel_size=3,padding='same'),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        Conv2D(64,kernel_size=3,padding='same'),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        keras.layers.MaxPool2D(2),\n",
        "        Conv2D(128,kernel_size=3,padding='same'),\n",
        "        BatchNormalization(),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        Conv2D(128,kernel_size=3,padding='same'),\n",
        "        BatchNormalization(),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        Dropout(0.3),\n",
        "        Flatten(),\n",
        "        # First Hidden Layer\n",
        "        Dense(128),\n",
        "        BatchNormalization(),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        Dropout(0.5),\n",
        "        # Output Layer\n",
        "        Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizers = Nadam()\n",
        "\n",
        "model.compile(optimizer=optimizers,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,y_train,batch_size=32,epochs=100,validation_split=0.2,callbacks=callbacks)\n",
        "\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1048704   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,329,290\n",
            "Trainable params: 1,328,522\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "   2/1250 [..............................] - ETA: 2:08 - loss: 3.3824 - accuracy: 0.0469  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_train_batch_end` time: 0.1901s). Check your callbacks.\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 1.4306 - accuracy: 0.4996 - val_loss: 1.1014 - val_accuracy: 0.6090\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0170 - accuracy: 0.6439 - val_loss: 1.3200 - val_accuracy: 0.5618\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8978 - accuracy: 0.6891 - val_loss: 0.9062 - val_accuracy: 0.6899\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8180 - accuracy: 0.7158 - val_loss: 0.9951 - val_accuracy: 0.6564\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7537 - accuracy: 0.7385 - val_loss: 0.7729 - val_accuracy: 0.7351\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.7008 - accuracy: 0.7585 - val_loss: 0.9903 - val_accuracy: 0.6676\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6616 - accuracy: 0.7715 - val_loss: 0.7785 - val_accuracy: 0.7354\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6152 - accuracy: 0.7864 - val_loss: 0.6490 - val_accuracy: 0.7777\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5781 - accuracy: 0.7997 - val_loss: 0.6699 - val_accuracy: 0.7758\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5474 - accuracy: 0.8115 - val_loss: 0.6768 - val_accuracy: 0.7801\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5193 - accuracy: 0.8192 - val_loss: 0.6816 - val_accuracy: 0.7730\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4936 - accuracy: 0.8286 - val_loss: 0.6894 - val_accuracy: 0.7695\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4627 - accuracy: 0.8387 - val_loss: 0.6490 - val_accuracy: 0.7888\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4420 - accuracy: 0.8467 - val_loss: 0.7583 - val_accuracy: 0.7524\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4256 - accuracy: 0.8524 - val_loss: 0.6466 - val_accuracy: 0.7920\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3987 - accuracy: 0.8615 - val_loss: 0.6491 - val_accuracy: 0.7948\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3847 - accuracy: 0.8651 - val_loss: 0.6528 - val_accuracy: 0.7956\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3607 - accuracy: 0.8717 - val_loss: 0.6668 - val_accuracy: 0.7887\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3398 - accuracy: 0.8798 - val_loss: 0.6722 - val_accuracy: 0.7931\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3268 - accuracy: 0.8855 - val_loss: 0.7882 - val_accuracy: 0.7727\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3112 - accuracy: 0.8922 - val_loss: 0.7677 - val_accuracy: 0.7752\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2942 - accuracy: 0.8953 - val_loss: 0.7135 - val_accuracy: 0.7897\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2835 - accuracy: 0.9000 - val_loss: 0.6607 - val_accuracy: 0.8063\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2667 - accuracy: 0.9069 - val_loss: 0.6970 - val_accuracy: 0.8023\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2663 - accuracy: 0.9072 - val_loss: 0.6767 - val_accuracy: 0.8045\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6675 - accuracy: 0.7867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6675499081611633, 0.7867000102996826]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vYEktgmygnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}